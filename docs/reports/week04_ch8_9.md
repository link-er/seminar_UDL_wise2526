# Report â€“ Week 04: Performance & Regularization



**Presenters:** Ben Halima Ibrahim, Zoghlami Fadi 

**Date:** 10.11.2025 



## Summary

### Chapter 8: Measuring performance

**I - Training a simple model:**

A neural network with **sufficient capacity** will mostly perform well on the training dataset. However, this does not mean that it will generalize well on the testing dataset (which is normally new and unseen data for the model). This causes a big problem especially for real-world scenarios, where the model'performance has to be as good as possible. <br>
==> Our goal is to train a model that **generalizes well on new data**

The test errors have three distinct causes:
- the inherent uncertainty in the task
- the amount of training data
- the choice of model

In the first section of this chapter, a simple model is trained on the [**MNIST-1D**](https://arxiv.org/pdf/2011.14439) dataset, which is 1D analogue of the **MNIST** dataset: each data example is created by randomly transforming one of the templates and adding noise.

![MNIST-1D dataset]()

**II - Sources of error:**

**III - Reducing error:**

**IV - Hyperparameters:**

### Chapter 9: Regularization (TO DO !!)

## Discussion Notes

\- Key questions raised during seminar

\- Open problems or unclear points



## References

- IBM - What is overfitting ? [[Link]](https://www.ibm.com/think/topics/overfitting)
